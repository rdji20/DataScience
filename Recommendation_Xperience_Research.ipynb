{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6526f5ec-73d5-4947-bac2-40c7c9d7c1a0",
   "metadata": {},
   "source": [
    "# Recommendation Experience (RX) Research\n",
    "by Roberto Infante\n",
    "\n",
    "This research consists on the exploration of multiple topics which together emerge in Recommendation Experience (RX). These topics include decision theory, choice architecture, behavioral economics, behavioural science, and social psychology. The motivation for this research is that I'm creating a recommendation engine for user personalization of real world activities to do in a city. I'm using OpenAI GPT-3 language model to get the embedded vectors from the place's descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e739e2-553f-4870-b759-9dc1fc4c2ae3",
   "metadata": {},
   "source": [
    "## Decision Theory\n",
    "Decision theory, as written by the stanford enyclopedia of philosophy, is concerned with the reasoning underlying an agent's choices, whether this is a mundane choice between taking the bus or getting a taxi, or a more far-reaching choice about whether to pursue a demanding political career. Decsion theory is as much a theory of beliefs, desires and other relevant attitudes as it is a theory of choice; what matters is how these various attitudes (preference attitudes) cohere together. \n",
    "\n",
    "The focus of this is a normative decision theory, which means that the main question is to understand the preference attitudes should satisfy in any generic circumstance. This amounts to minimal account of *rationality*. The key issue for a minimal account is the treatment of uncertainty. (EU) expected utility theory says that in situations of uncertainty one should prefer the option with the greatest expected desirability or value. \n",
    "\n",
    "We understand that preference is a comparative attitude. When an agent prefers option A over B, we mean that the agent takes A ro be more desirable or choice-worthy than B. When there are more than 2 options (E.g. A,B,C,D and E) we speak of this preference as an agent's preference ordering. We then have to axioms that have to be met in order to support the rational preference over options. <br>\n",
    ">The axiom of completeness <br>\n",
    "That for any A,B ∈ S : either A⪯B or B⪯A. <br>\n",
    "The axiom of transitivity <br>\n",
    "For any A,B,C∈S: if A⪯B and B⪯C then A⪯C. <br>\n",
    "\n",
    "As long as the set of prospect/options is finite, any weak order of the options in S can be represented by an ordinal utility function. For any A,B in S : u(A) <= u(B) means that A has as weak or weaker order than B. \n",
    "\n",
    "With this we can have the Theorem of Ordinal Representation. Let S be a finite set, and ⪯ a weak preference relation on S. Then there is an ordinal utility function that represents ⪯ just in case ⪯ is complete and transitive. \n",
    "\n",
    "There is one problem with this theorem though. We can have an order of let's say A,B,C; but we don’t know the cardinal distance between them. We want to know how much better an option is than the others. This is why Ramsey and von Neumann and Morgensten constructed a new option L (or the lottery option) that has A and C as its possible prices. The basic idea is that the judgment about B relative to C on the one hand and A on the other, can be measured by the riskiness of the lottery L involving C and A tat you deem equally as desirable as B. The main word here is indifference. When the agent is indifferent of doing activity B or entering the lottery and having the opportunity to do activity C 3/4 of the time; this means that activity B has a **utility** of 3/4 if utility of the activity that the person least wants to do is 0 (A=0) and the activity that the person wants to do the most is 1 (C=1).\n",
    "\n",
    "We have to understand though that since the utilities of options can only be determined relative to the utilities of other options, there is no such thing as the absolute utility of an option. Second, by the same reasoning, neither interval-valued nor ordinal utility measures are interpersonally commensurable with respect to levels and units of utility. \n",
    "\n",
    "This is all good but to fill the gaps in reasioning about the assumption that lotteries are evaluated in terms of expected utility, we can analyze the vNM theorem which shores up the gaps by shifting the attention back to the preference relation.\n",
    "\n",
    "Let us first define, in formal terms, the expected utility of a lottery: Let Li be a lottery from the set L of lotteries, and Oik the outcome, or prize, of lottery Li that arises with probability pik. The expected utility of Li is then defined as:\n",
    "\n",
    "\n",
    "here is the vNM equation:\n",
    "$$ EU(L_i) =  \\sum_{k} u(O_{ik}) * p_{ik}  $$\n",
    "\n",
    "This adds two other axioms. \n",
    ">The axiom of continuity <br>\n",
    "Suppose A⪯B⪯C. Then there is a p∈[0,1] such that {pA, (1-p)C} ~ B <br>\n",
    "The axiom of independence <br>\n",
    "Suppose A⪯B. Then for any C and any p∈[0,1]: {pA, (1-p)C} ⪯ {pB, (1-p)C} <br>\n",
    "\n",
    "### The question here is: How to compute the utility value with implicit interactions? Or if it cannot be this way, how can we explicitely compute the utility value (using L set) without diminishing the RX?\n",
    "\n",
    "A good KPI to see if we are diminishing the RX is by analysing by keeping the same variables constant and check how the churn behaves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a45260-4c9c-4b2d-be01-c1f9d625bca6",
   "metadata": {},
   "source": [
    "### Agent's preference ordering\n",
    "I'm going to test a utility function by using the agent's ordering as the main input for the content based activity recommendations order. This means that depending on the order I'm going to use the axiom of independence in order to arrange the cards and maximize the expected utility. This is a form of using explicit interaction for L computation.\n",
    "\n",
    "Here the preference ordering is tricky because the least value is not supposed to be something that the person doesn't want to do but rather something that is not as desirable as the first one.\n",
    "\n",
    "The first approach I will use is to have predefined values of desirability which are going to be part of the utility function. In this case I will have values from 1 to 3 to categorize the activities (1 being the least desirable and 3 the most)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857041a6-1b69-46da-b699-33480b3fbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cf6e48-408b-4083-b9c6-a358ecb34d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uploading activities descriptions with embeddings computed with GPT-3\n",
    "with open(\"cards_embeddings_cache_raw.pkl\", \"rb\") as description_embeddings_try:\n",
    "    description_embeddings = pickle.load(description_embeddings_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6941cbb2-c7a0-4d16-910f-fcf79153fcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7986"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check to see if load worked\n",
    "\n",
    "len(description_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b915d1-d507-43ba-a3fb-968571368dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4680, 266, 3513, 3953, 4735, 121, 1688, 3789, 6662, 4024, 6746, 2273, 5353, 6640, 1312, 281, 4265, 4014, 2685, 623]\n"
     ]
    }
   ],
   "source": [
    "## Dict to store the ordering.\n",
    "## I'm going to choose randomly a set of cards when later I will use my ontology to decide what things \n",
    "## I want to do an what I don't. \n",
    "\n",
    "import random\n",
    "samples = 20\n",
    "random.seed(10)\n",
    "activity_cards = []\n",
    "\n",
    "for i in range(samples):\n",
    "    card = random.randint(0,(len(description_embeddings) - 1))\n",
    "    activity_cards.append(card)\n",
    "print(activity_cards)\n",
    "\n",
    "\n",
    "preference_ordering = {\"1\":[], \"2\":[], \"3\":[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546f7af-c6f4-41f8-8fda-b1251155a549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
